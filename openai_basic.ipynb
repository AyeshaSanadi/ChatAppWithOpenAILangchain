{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324d651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6dc238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481ce552",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "completion = client.chat.completions.create(model = \"gpt-4\",\n",
    "                                            messages = [\n",
    "                                                        {'role': \"system\", \"content\": \"You are a helpful assistant thatanalyzes the sentiment of the user's message as Positive, Negative, or Neutral. Only return one of those three words.\"},\n",
    "                                                        {\"role\": \"user\", \"content\": \"I am really happy with your service!\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ad7dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C85mvuCyIkTTjuhQBtRFWIoxQIR3d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Positive', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1756044909, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=50, total_tokens=51, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703b5832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d92603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using chat completion different parameter.\n",
    "\n",
    "## seed: Optional[int]\n",
    "### A number to make outputs reproducible. If the same prompt and seed are used, the response will be the same.\n",
    "### Default: None (random output each time)\n",
    "\n",
    "## max_tokens: Optional[int]\n",
    "### The maximum number of tokens to generate in the response.\n",
    "### This limits how long the reply can be.\n",
    "### Default: Varies by model. If not set, OpenAI chooses based on model limits.\n",
    "\n",
    "## temperature: Optional[float]\n",
    "### Controls randomness of the response. Lower = more predictable, higher = more creative.\n",
    "### Range: 0.0 to 2.0\n",
    "### Default: 1.0\n",
    "\n",
    "## stream: Optional[bool]\n",
    "### If true, partial message deltas will be sent as the model generates the response.\n",
    "### Useful for real-time applications.\n",
    "### Default: false\n",
    "respone = client.chat.completions.create(model = \"gpt-4\",\n",
    "                                        messages = [{\"role\":\"user\", \"content\": \"Why Ichalkaranji is famous?\"}],\n",
    "                                        max_tokens = 50,\n",
    "                                        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c53aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ichalkaranji is famous for its textile industry, particularly for its production of cotton sarees and other clothing materials. It is often referred to as the \"Manchester of Maharashtra\" due to its significant contribution to the textile sector of the state. The'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respone.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1698116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "respone = client.chat.completions.create(model = \"gpt-4\",\n",
    "                                        messages = [{\"role\":\"user\", \"content\": \"Why Ichalkaranji is famous?\"}],\n",
    "                                        max_tokens = 50,\n",
    "                                        temperature = 2,\n",
    "                                        stream = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "804a8d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x1de510ea850>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respone  #Object of stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5548a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in respone:\n",
    "    print(i)\n",
    "    # print(i.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144f0d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
